[
  {
    "objectID": "posts/2023-01-05/index.html",
    "href": "posts/2023-01-05/index.html",
    "title": "05.01.23",
    "section": "",
    "text": "This is my attempt to build a Rescorla-Wagner (RW) model, and apply it to FLARe data. This model will be built using Stan. I will start with a basic model, and increase complexity as I go.\nI am using a random sample of 10 participants. They will be from multiple studies, so this cannot be considered ‘peeking’ at the data. The aim is to make the output parameter distributions look reasonable, then apply the model to more data.\nThe data files are made via another script. I will convert data from scratch at a later time.\n\n\n\n\n        black        orange       skyblue   bluishgreen        yellow \n    \"#000000\"     \"#E69F00\"     \"#56B4E9\"     \"#009E73\"     \"#F0E442\" \n         blue    vermillion reddishpurple          gray \n    \"#0072B2\"     \"#D55E00\"     \"#CC79A7\"     \"#999999\" \n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nLoading required package: StanHeaders\n\nrstan (Version 2.21.7, GitRev: 2e1f913d3ca3)\n\nFor execution on a local, multicore CPU with excess RAM we recommend calling\noptions(mc.cores = parallel::detectCores()).\nTo avoid recompilation of unchanged Stan programs, we recommend calling\nrstan_options(auto_write = TRUE)\n\n\nAttaching package: 'rstan'\n\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n\n\n\n\n\n\n\n\n\n\n\nI can plot these 10 participants, to somewhat recreate the acquisition plots in the literature. This shows an initial shape to the acquisition, at individual level, but is usually averaged for further analysis.\nI can also show some individual plots, to show a relationship between US and expectancy ratings. This is where the learning rate parameter, alpha, is demonstrated. And possibly tau, the choice variability / consistency parameter\n\n## Create a tibble to plot the 10 participants. Some manipulation of variable type to make plotting easier, such as subject number as factor so colours are distinct on graph, rather than a gradient which is the default for continuous data or integer type. Trial number as integer so it sorts the x axis in numerical order. You can make it factor and specify the order with a vector, but I dont want to type out all that. \n\nplus_plot <- plus_sample %>% \n  add_column(subject = 1:10, .before = TRUE) %>% \n  pivot_longer(\n  !subject,\n  names_to = 'trial',\n  values_to = 'rating') \nplus_plot$trial <- gsub('X','',as.character(plus_plot$trial))\nplus_plot$trial <- as.integer(plus_plot$trial)\nplus_plot$subject <- as.factor(plus_plot$subject)\n\n## Separate tibble to plot the mean and sd of the 10 participants. \n\nmean_plus_plot <- plus_plot %>% \n  group_by(trial) %>% \n  summarise(mean_expectancy_rating_per_trial = mean(rating, na.rm = TRUE), sd_expectancy_rating_per_trial = sd(rating, na.rm = TRUE))\n\n## Better attempt at graphing from two tibbles. Not sure how to fix error bars yet. \n  \nggplot(NULL) +\n  geom_point(data = plus_plot, aes(x = trial, y = rating, group = subject, colour = subject)) +\n  geom_line(data = plus_plot, aes(trial, rating, group = subject, colour = subject)) +\n  scale_x_continuous(breaks = seq(1,12,1)) +\n  scale_y_continuous(breaks = seq(1,9,1)) +\n  geom_line(data = mean_plus_plot, aes(x = trial, y = mean_expectancy_rating_per_trial)) +\n  geom_point(data = mean_plus_plot, aes(x = trial, y = mean_expectancy_rating_per_trial), size = 3)\n\n\n\n  # geom_errorbar(data = mean_plus_plot, aes(x = trial, ymin = mean_expectancy_rating_per_trial - sd_expectancy_rating_per_trial, ymax = mean_expectancy_rating_per_trial + sd_expectancy_rating_per_trial), width = 0.2)"
  },
  {
    "objectID": "posts/2023-01-17/17.01.23.html",
    "href": "posts/2023-01-17/17.01.23.html",
    "title": "17.01.2023",
    "section": "",
    "text": "int x[y];\nMeans y instances of your variable x if x is [1,2,3], y should be 3\nvector[x] y[z]\nMeans a vector called y, with z columns, and x rows. Or a vector of z instances of x element vectors.\n\\(\\left[ \\begin{array}{} 1 & 1 & ... & z \\\\ 2 & 2 & ... & z \\\\ ... & ... & ... & z\\\\ x & x & x & x \\end{array} \\right]\\)\n\n\n\nValue is the internal associative value of a participant. I initially tried to keep the RW model simple, and enforce a 1:1 mapping of value to choice (expectancy ratings). But for the life of me, and after a week invested in Stan, it just wouldn’t work. The outputs were identical if I commented out the model section, as when it was active.\nIt was only when choice is linked via a distribution to value, that it actually works.\nQuite why it cant estimate a simple learning rate, without this linking distribtiuon, I do not know. More reading required, perhaps.\nThe Lei Zhang models all use a softmax (categorical logistic regression), which I didn’t see the importance of. This obviously wont apply to scales of 1-9.\nOther distributions to try will be normal, and the beta distribution, which allows for more accuracy.\nI finally get the reason for the beta distribution!"
  },
  {
    "objectID": "posts/2023-02-28/index.html",
    "href": "posts/2023-02-28/index.html",
    "title": "Plan for March",
    "section": "",
    "text": "Problems\nThe data are untidy, and I cannot make inferences from them. It is not discretised to individual studies. There are missing data such as scream patterns and CS+/CS- orders.\nThe models built are complex, have many parameters, and require some significant data transformations.\nThe models don’t work well, they are rigid. They do not capture much of the volatility in the data. The generated data distributions are uninformative. The information criterions are bonkers, preventing me from comparing models.\nA Bayesian significance test should be used given the model. In addition, null models and other sanity checks should be used.\n\n\nThe Correct Pipeline per the Literature\nReferencing this Wilson & Collins (2019) paper\n\nTheorise a set of models which all have a chance to realistically capture the data. This can include null models such as random button pressing. (Also just fit a curve)\n\n\n\nSimulate data. Using the models, set the free parameters via a random choice from a distribution, and generate simulated data. Then run this data back through the model, to see if it can recover the parameters correctly. Do this several times iteratively, to see if the models can cope with many parameter settings, which is indicative that they can actually estimate free parameters from real data. (Run a KL divergance score here?)\nPlot the correlation between real and recovered parameters, looking for a correlation above a certain level, >0.5 correlation say. Plotting will show biases or areas where there is large divergance.\n\nnb- some models will only work within certain parameter ranges, so completely random parameters may not work, and might need to be bounded within realistic limits.\n\nCompare different models using an information criterion, or cross validation. This can be plotted in a confusion matrix, which validates model comparison via model recovery on simulated data. (Is simulated data from model A best fit by model A, or model B, C etc. per BIC/WAIC). Confusion matrix should be an identity matrix. If not, look into running an inversion matrix.\nRun models with real data. You can further simulate to find biases, such as left/right biases, or optimism biases, which affect choice above basic model. Validation should be via a posterior predictive check, i.e. by simulating data with the fit parameter values. This leads to a winning model.\nExtract latent variables from the model. These can be correlated with physiological data, especially their evolution over time. You can also study individual differences, using fit parameters as dependent variable in continuous analyses, correlating with age or symptoms, or group comparisons.\n\n\n\nLearning Still to do\nLog Likelihood and model comparisons therein. I still don’t quite understand exactly what this is measuring, and hence why the model comparisons aren’t working. I have found a lecture series which explains this in more detail than Lei Zhang’s course.\nDirichlet distributions for discrete data. I think this is a better fit for the experiment than a beta distribution alone. This tutorial might explain things\n\n\nRelevant Papers\nHopkins, A. K., Dolan, R., Button, K. S., & Moutoussis, M. (2021). A Reduced Self-Positive Belief Underpins Greater Sensitivity to Negative Evaluation in Socially Anxious Individuals. Computational Psychiatry, 5(1), 21–37. DOI: http://doi.org/10.5334/cpsy.57 paper supplement\nThis paper contains beta distributions, and aims to explain anxious participants learning more from negative experiences. Good clear explanations in supplement.\nWise T, Michely J, Dayan P, Dolan RJ (2019) A computational account of threat-related attentional bias. PLoS Comput Biol 15(10): e1007341. https://doi.org/10.1371/journal.pcbi.1007341 paper\nThis paper uses ‘leaky beta distributions’, I think in place of RL. It also examines attentional processes, via a Pierce-Hall adaptation, which might better model decay/boredom.\n\n\nPlan\n\nBuild a set of models in R, to simulate data.\n\n\nNull - random button pressing\nNull - single button pressing\nCurve - polynomial regression\nRL - RW/Beta two parameters (alpha (LR) and sigma (variance))\nRL - RW/Beta three parameters (reward alpha and punishment alpha (LR) and sigma (variance))\nRL - RW/Dirichet two parameters\nRL - RW/Dirichet three parameters\n\n\nRebuild above in Stan, and compare these models per Wilson paper, including correlations and confusion matrices.\nMake a better real dataset to work from, perhaps going back to source to find correct patterns. :cold_sweat:\nRun the best models with real data.\nPossibly look to pre-register at this point, prior to running correlations with phenotype data.\n\n\n\nTimeframe\nThere are no major obstacles or life events in March. I have four relatively clear weeks to do this work, prior to running the Paris Marathon on April 2nd, where I will take a week off post.\nThis week, i.e. by Friday 3rd, I hope to build the R models.\nIn the week commencing 6th March, I will rebuild these in Stan, and start model comparisons.\nW/C 13th March, I will apply these to the real data, if on schedule.\nW/C 20th March, I will continue to apply these to real data.\nW/C 27th March, I will write up the pre-registration.\nLonger term, I hope to present results in June, and a poster in July."
  },
  {
    "objectID": "posts/2023-01-30/index.html",
    "href": "posts/2023-01-30/index.html",
    "title": "test",
    "section": "",
    "text": "Header\n\na <- 34\nprint(a)\n\n[1] 34\n\nhist(a)"
  },
  {
    "objectID": "posts/2023-01-31/index.html",
    "href": "posts/2023-01-31/index.html",
    "title": "The Beta Distribution via Mean and SD",
    "section": "",
    "text": "Assuming choice (expectancy rating) is drawn from a beta distribution:\n\\(Choice \\sim Beta(\\alpha , \\beta)\\)\nThen the mean and variance should be per this textbook\n\\(\\mu = \\frac{\\alpha}{\\alpha + \\beta}\\)\n\\(\\sigma^2 = \\frac{\\alpha\\beta}{(\\alpha + \\beta)^2(\\alpha + \\beta + 1)}\\)\nThinking of the beta distribution as all the choices the participant could make based on their associative value for that trial, it makes sense to cast the mean as Value, and the variance / standard deviation as something for Stan to estimate. This variance, representing uncertainty, or optimism / pessimism, or some other set of biases, is likely to differ between participants, and indeed might vary trial to trial.\nThe internet gives many different rearranged versions of the above equations, putting alpha and beta on the LHS. For example\n\\(\\alpha = \\left(\\frac{1-\\mu}{\\sigma^2} - \\frac{1}{\\mu}\\right)\\mu^2\\)\n\\(\\beta=\\alpha \\left(\\frac{1}{\\mu}-1\\right)\\)\nHowever, this only works within certain bounds:\n\\(\\mu \\in (0,1)\\)\n\\(\\sigma^2 \\in (0,0.5^2)\\) (given variance cannot be lower than \\(\\mu(1-\\mu)\\) term\nSo I can either constrain this parameter in Stan excessively, or find another way to estimate the parameters.\nThis is another way:\n\\(\\alpha = \\mu(\\frac{\\mu(1 - \\mu)}{\\sigma - 1})\\)\n\\(\\beta = (1 - \\mu)(\\frac{\\mu(1 - \\mu)}{\\sigma - 1})\\)\nGleaned from this website.\nI’ll need to look into this, to see if it is valid. I will go with it for now, as it seems to work."
  },
  {
    "objectID": "posts/2023-01-30.2/RL_23.01.23.html",
    "href": "posts/2023-01-30.2/RL_23.01.23.html",
    "title": "RL_30.01.23",
    "section": "",
    "text": "Functions\n\n\n\nData\n\n\n\n\nIntroduction\nTo use computational / cognitive modelling approaches to extract more parameters from FLARe data, which can later be used to a) find differences between measurements of groups (in validation study), and/or b) to correlate with genetic or phenotypic data from TEDS and/or GLAD.\nThe software used to build models and extract parameters is Stan. Stan allows one to program bayesian models, capturing and using the uncertainty within parameter estimation (rather than using means per frequentist approaches).\nA simple example is using Stan to estimate the probability of a biased coin. If we flip a coin 12 times, and see 9 heads, we might assume the pribability of heads is 0.75. However, this is based on limited data, and you cant measure/show the uncertainty.\nYou want to know the probability of the coin being biased to 0.75 heads, given the data of 9 heads in 12 trials. Theta represents the model, or (unknown) probability.\ni.e. \\(p(Heads\\mid N,\\theta)\\)\nAnd the number of heads will pertain to the binomial distribution:\n\\(heads \\sim Binomial(N,\\theta)\\)\n\n\ndata { //known observation data\n  int<lower=0> h;\n  int<lower=0> N;\n}\n\nparameters {\n  real<lower=0, upper=1> theta;\n}\n\nmodel {\n  // theta ~ uniform(0,1);\n  h ~ binomial(N, theta);\n}\n\ngenerated quantities {\n  real log_lik;\n  int heads;\n  \n  log_lik = binomial_lpmf(h | N, theta);\n  heads = binomial_rng(N, theta);\n  \n}\n\nStan uses Markov Chain Monte Carlo sampling, to estimate the parameter. One chain is run per CPU core. Each chain samples a point on the distribution. It is rewarded for samples near the peak/mean of the distribution. It then moves to another area of the distribution. In this instance, it does this 1000 times. Given the reward, it thus converges around this mean, which you can see in the trace plot.\nThis probability density function (PDF), graphically shows the uncertainty contained within the parameter estimate. The red area denotes the highest density interval (HDI), set here to its default of 0.8/80%. If more data were introduced, the uncertainty would reduce.\nStan can also generate data based upon the parameter estimate, from the 4*1000 samples. The histogram shows 9 heads being the most likely based on the 4*1000 samples.\n\n\n\nSAMPLING FOR MODEL 'a57dca310d1928b2ee4bc7cb5276c4f4' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 2.3e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.23 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.006035 seconds (Warm-up)\nChain 1:                0.005662 seconds (Sampling)\nChain 1:                0.011697 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'a57dca310d1928b2ee4bc7cb5276c4f4' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 3e-06 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.03 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.005922 seconds (Warm-up)\nChain 2:                0.005879 seconds (Sampling)\nChain 2:                0.011801 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'a57dca310d1928b2ee4bc7cb5276c4f4' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 3e-06 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.03 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.005936 seconds (Warm-up)\nChain 3:                0.00565 seconds (Sampling)\nChain 3:                0.011586 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'a57dca310d1928b2ee4bc7cb5276c4f4' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 2e-06 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.02 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.006282 seconds (Warm-up)\nChain 4:                0.005848 seconds (Sampling)\nChain 4:                0.01213 seconds (Total)\nChain 4: \n\n\n$summary\n              mean     se_mean        sd        2.5%        25%        50%\ntheta    0.7132458 0.002977411 0.1173131   0.4622676  0.6346924  0.7232075\nlog_lik -1.8128515 0.015684167 0.6319924  -3.5720612 -1.9772618 -1.5695601\nheads    8.5695000 0.044862658 2.0776787   4.0000000  7.0000000  9.0000000\nlp__    -8.9031007 0.018172299 0.7260527 -11.0087807 -9.0722529 -8.6189080\n               75%      97.5%    n_eff     Rhat\ntheta    0.7994954  0.9087166 1552.443 1.004564\nlog_lik -1.4005660 -1.3549262 1623.681 1.002898\nheads   10.0000000 12.0000000 2144.800 1.002835\nlp__    -8.4350018 -8.3762300 1596.307 1.003694\n\n$c_summary\n, , chains = chain:1\n\n         stats\nparameter       mean        sd        2.5%        25%        50%        75%\n  theta    0.7034403 0.1220785   0.4499461  0.6207978  0.7150049  0.7961614\n  log_lik -1.8495497 0.6713904  -3.6680190 -2.0153223 -1.6051594 -1.4084611\n  heads    8.4690000 2.1108042   4.0000000  7.0000000  9.0000000 10.0000000\n  lp__    -8.9207156 0.7102808 -10.9576006 -9.1610119 -8.6449259 -8.4421599\n         stats\nparameter      97.5%\n  theta    0.8968506\n  log_lik -1.3548804\n  heads   12.0000000\n  lp__    -8.3762945\n\n, , chains = chain:2\n\n         stats\nparameter       mean        sd        2.5%        25%        50%        75%\n  theta    0.7080988 0.1166642   0.4570998  0.6335021  0.7177761  0.7927339\n  log_lik -1.8120667 0.6505674  -3.6454792 -1.9772742 -1.5570039 -1.3985253\n  heads    8.4890000 2.0890771   4.0000000  7.0000000  9.0000000 10.0000000\n  lp__    -8.8874360 0.7311442 -10.7931361 -9.0483744 -8.5967650 -8.4265006\n         stats\nparameter      97.5%\n  theta    0.9017759\n  log_lik -1.3548051\n  heads   12.0000000\n  lp__    -8.3761784\n\n, , chains = chain:3\n\n         stats\nparameter       mean        sd        2.5%       25%        50%       75%\n  theta    0.7130037 0.1120249   0.4731105  0.636666  0.7214262  0.791345\n  log_lik -1.7785873 0.5933537  -3.4430740 -1.932749 -1.5431655 -1.395346\n  heads    8.5680000 1.9766849   4.0000000  7.000000  9.0000000 10.000000\n  lp__    -8.8597447 0.7001664 -10.8360958 -9.012821 -8.5883750 -8.427869\n         stats\nparameter      97.5%\n  theta    0.9062153\n  log_lik -1.3548590\n  heads   12.0000000\n  lp__    -8.3762556\n\n, , chains = chain:4\n\n         stats\nparameter       mean        sd        2.5%        25%        50%        75%\n  theta    0.7284403 0.1169341   0.4772971  0.6476205  0.7393609  0.8178019\n  log_lik -1.8112024 0.6084888  -3.4942731 -1.9486326 -1.5777260 -1.4043339\n  heads    8.7520000 2.1220271   4.0000000  7.0000000  9.0000000 10.0000000\n  lp__    -8.9445064 0.7594309 -11.2375994 -9.1174701 -8.6363056 -8.4409566\n         stats\nparameter      97.5%\n  theta    0.9191709\n  log_lik -1.3552179\n  heads   12.0000000\n  lp__    -8.3761907\n\n\nci_level: 0.8 (80% intervals)\n\n\nouter_level: 0.95 (95% intervals)\n\n\n\n\n\n\n\n\n\n\n\nNow to look at FLARe data, which, while more complex than a coin flip, shares some similarities. There is an unknown parameter to the participants, the reinforcement rate of the US (75%). They experience the US as happening or not happening, so could be said to be binomial in distribution. This happens over 12 trials.\nThe first plot shows 10 participants individual ratings over 12 trials, and the group mean in black. This individual variation is the thing I hope models can explain.\nThe second plot shows a single participant. This participant appears to do the experiment correctly, and reacts as expected to US. It also appears similar to the mean.\nFor now, for simplicity, I am just going to model the CS+ acquisition.\n\n\n\n\n\nWarning: Removed 3 rows containing missing values (geom_point).\n\n\n\n\n\n\n\n\nSimulation of RW and learning rates in R\nSimple graphs of RW updating.\nTop left graph is the actual data, plotted.\nThe three other graphs show the value updating, given low, medium, and high learning rates.\n\n\nThe RW model\n\\(\\alpha\\) - Learning rate (free parameter)\n\\(PE\\) - reward prediction error (reward - current expectation)\n\\(V\\) - value (subjective)\n\\(R\\) - reward (US = 1, no US = 0)\n\\(t\\) - trial (1,2,…,12)\n\\(\\text{Value Update: } V_t = V_{t-1}+\\alpha*PE_{t-1}\\)\n\\(\\text{Prediction Error: } PE_{t-1} = R_{t-1} - V_{t-1}\\)\n\\(V_t = V_{t-1} + \\alpha(R_{t-1} - V_{t-1})\\)\n\n\n\n\n\n\n\n\nData processing steps\nExpectancy rating of 1, 2, …, 9 is categorical. I have scaled this to a continuous distribution between 0 and 1, to represent (participant’s subjective) probability.\nScale is 9 steps between \\(\\frac{0.5}{9}\\) and \\(1\\) in \\(\\frac{1}{9}\\) increments.\nUS / Scream is considered a ‘reward’, and has value of \\(1\\). No US has a value of \\(0\\).\n\n\n\nModel 1 - Rescorla Wagner, Choice ~ Normal(value,sigma)\n\nModel and Parameters\nRW value updating, via learning rate parameter \\(lr\\).\nValue mapped to participant choice / expectancy rating via a normal distribution. Mean \\(\\mu\\) is value for that trial. Sigma \\(\\sigma\\) is estimated by the model.\n\n\nOutputs\nLog Likelihood extracted per participant and trial. Leave one out cross validation (LOOCV) and WAIC calculated from this. (For model comparison)\nHistogram of generated data for trial 9, showing normal distribution.\nFinal plot is mean of generated choices from model in blue, and actual choice data, all from participant one. Not sure how to use this data yet, possibly some sort of divergance score.\n\n\ndata {\n  int<lower=1> ntrials;          \n  int<lower=1> nsub;\n  real<lower=0,upper=1> choice[nsub,ntrials]; //array of size nTrials (12 intigers)\n  real<lower=-1, upper=1> reward[nsub,ntrials]; \n}\n\nparameters {\n  real<lower=0,upper=1> lr[nsub];\n  real<lower=0> sigma[nsub];  \n}\n\nmodel {\n\n  real v[nsub,ntrials];\n  real pe[nsub,ntrials];       // prediction error\n  \n  for (s in 1:nsub) {\n  v[s,1] = 0.5;\n\n  for (t in 1:(ntrials-1)) { \n    \n    pe[s,t] = reward[s,t] - v[s,t];\n\n    v[s,t+1] = v[s,t] + lr[s] * pe[s,t]; \n  }  \n  \n  for (t in 1:ntrials) {\n\n    choice[s,t] ~ normal (v[s,t],sigma[s]);\n  }\n}\n}\n\ngenerated quantities {\n  real log_lik[nsub,ntrials];\n  real choice_pred[nsub,ntrials];\n  \n  choice_pred = rep_array(-999,nsub,ntrials);\n  \n  {\n  real v[nsub,ntrials];\n  real pe[nsub,ntrials];      \n  \n  for (s in 1:nsub) {\n  v[s,1] = 0.5;\n\n  for (t in 1:(ntrials-1)) { \n    \n    pe[s,t] = reward[s,t] - v[s,t];\n\n    v[s,t+1] = v[s,t] + lr[s] * pe[s,t]; \n  }  \n  \n  for (t in 1:ntrials) {\n    log_lik[s,t] = normal_lpdf(choice[s,t] | v[s,t],sigma[s]);\n    choice_pred[s,t] = normal_rng(v[s,t],sigma[s]);\n  }\n}\n  }\n}\n\n\n\n\nSAMPLING FOR MODEL '5875f43ba02dc332fb6935055510e2bc' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 5.4e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.54 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.255058 seconds (Warm-up)\nChain 1:                0.199984 seconds (Sampling)\nChain 1:                0.455042 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL '5875f43ba02dc332fb6935055510e2bc' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 2.2e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.22 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.268286 seconds (Warm-up)\nChain 2:                0.208163 seconds (Sampling)\nChain 2:                0.476449 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL '5875f43ba02dc332fb6935055510e2bc' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 2.2e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.22 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.2629 seconds (Warm-up)\nChain 3:                0.199783 seconds (Sampling)\nChain 3:                0.462683 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL '5875f43ba02dc332fb6935055510e2bc' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 1.9e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.275355 seconds (Warm-up)\nChain 4:                0.208926 seconds (Sampling)\nChain 4:                0.484281 seconds (Total)\nChain 4: \n\n\n\n\n\nci_level: 0.8 (80% intervals)\n\n\nouter_level: 0.95 (95% intervals)\n\n\n\n\n\nci_level: 0.8 (80% intervals)\nouter_level: 0.95 (95% intervals)\n\n\n\n\n\nWarning: Relative effective sample sizes ('r_eff' argument) not specified.\nFor models fit with MCMC, the reported PSIS effective sample sizes and \nMCSE estimates will be over-optimistic.\n\n\nWarning: Some Pareto k diagnostic values are too high. See help('pareto-k-diagnostic') for details.\n\n\nWarning: \n9 (7.5%) p_waic estimates greater than 0.4. We recommend trying loo instead.\n\n\n\n\n\n\n\n\n\n\n\nModel 2 - Rescorla Wagner, Choice ~ Beta(alpha,beta)\n\nModel and Parameters\nRW value updating, via learning rate parameter \\(lr\\).\nValue mapped to participant choice / expectancy rating via a beta distribution. Mean \\(\\mu\\) is value for that trial. Sigma \\(\\sigma\\) is estimated by the model. (and called beta)\nBeta distribution is more flexible than normal. It is governed by two shaping parameters, alpha and beta. These can be derived from mean and variance:\n\\(\\alpha = \\mu(\\frac{\\mu(1 - \\mu)}{\\sigma - 1})\\)\n\\(\\beta = (1 - \\mu)(\\frac{\\mu(1 - \\mu)}{\\sigma - 1})\\)\n\n\nOutputs\nAs model 1. Log Likelihood extracted per participant and trial. Leave one out cross validation (LOOCV) and WAIC calculated from this. (For model comparison)\nHistogram showing generated data of trial 9, showing beta distribution, skewed towards high probability.\nFinal plot is mean of generated choices from model in blue, and actual choice data, all from participant one.\n\n\ndata {\n  int<lower=1> ntrials;          \n  int<lower=1> nsub;\n  real<lower=0,upper=1> choice[nsub,ntrials]; //array of size nTrials (12 intigers)\n  real<lower=-1, upper=1> reward[nsub,ntrials]; \n}\n\nparameters {\n  real<lower=0,upper=1> lr[nsub];\n  real<lower=0> beta[nsub];  \n}\n\nmodel {\n\n  real v[nsub,ntrials];\n  real pe[nsub,ntrials];       // prediction error\n  \n  real shape_alpha[nsub,ntrials];\n  real shape_beta[nsub,ntrials];\n  \n  //beta ~ normal(0,1);\n  \n  for (s in 1:nsub) {\n  v[s,1] = 0.5;\n\n  for (t in 1:(ntrials-1)) { \n    \n    pe[s,t] = reward[s,t] - v[s,t];\n\n    v[s,t+1] = v[s,t] + lr[s] * pe[s,t]; \n  }  \n  \n  for (t in 1:ntrials) {\n    \n    shape_alpha[s,t] = v[s,t] * ((v[s,t] * (1-v[s,t]) / beta[s]));\n    shape_beta[s,t] = (1-v[s,t]) * ((v[s,t] * (1-v[s,t]) / beta[s]));\n    \n    choice[s,t] ~ beta(shape_alpha[s,t],shape_beta[s,t]);\n  }\n}\n}\n\ngenerated quantities {\n  real log_lik[nsub,ntrials];\n  real choice_pred[nsub,ntrials];\n  \n  choice_pred = rep_array(-999,nsub,ntrials);\n  \n  {\n  real v[nsub,ntrials];\n  real pe[nsub,ntrials];      \n  \n  real shape_alpha[nsub,ntrials];\n  real shape_beta[nsub,ntrials];\n  \n  for (s in 1:nsub) {\n  v[s,1] = 0.5;\n\n  for (t in 1:(ntrials-1)) { \n    \n    pe[s,t] = reward[s,t] - v[s,t];\n\n    v[s,t+1] = v[s,t] + lr[s] * pe[s,t]; \n  }  \n  \n  for (t in 1:ntrials) {\n    shape_alpha[s,t] = v[s,t] * ((v[s,t] * (1-v[s,t]) / beta[s]));\n    shape_beta[s,t] = (1-v[s,t]) * ((v[s,t] * (1-v[s,t]) / beta[s]));\n    \n    log_lik[s,t] = beta_lpdf(choice[s,t] | shape_alpha[s,t], shape_beta[s,t]);\n    choice_pred[s,t] = beta_rng(shape_alpha[s,t], shape_beta[s,t]);\n  }\n}\n  }\n}\n\n\n\n\nSAMPLING FOR MODEL 'f2f34ad5742d062c2187462b6d9968c2' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 0.000117 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 1.17 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.707985 seconds (Warm-up)\nChain 1:                0.714203 seconds (Sampling)\nChain 1:                1.42219 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'f2f34ad5742d062c2187462b6d9968c2' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 5e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.5 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.672371 seconds (Warm-up)\nChain 2:                0.656513 seconds (Sampling)\nChain 2:                1.32888 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'f2f34ad5742d062c2187462b6d9968c2' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 5.3e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.53 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.669537 seconds (Warm-up)\nChain 3:                0.701421 seconds (Sampling)\nChain 3:                1.37096 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'f2f34ad5742d062c2187462b6d9968c2' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 5.1e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.51 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.673223 seconds (Warm-up)\nChain 4:                0.640979 seconds (Sampling)\nChain 4:                1.3142 seconds (Total)\nChain 4: \n\n\n'pars' not specified. Showing first 10 parameters by default.\n\n\n\n\n\nci_level: 0.8 (80% intervals)\n\n\nouter_level: 0.95 (95% intervals)\n\n\n\n\n\nci_level: 0.8 (80% intervals)\nouter_level: 0.95 (95% intervals)\n\n\n\n\n\nWarning: Relative effective sample sizes ('r_eff' argument) not specified.\nFor models fit with MCMC, the reported PSIS effective sample sizes and \nMCSE estimates will be over-optimistic.\n\n\nWarning: Some Pareto k diagnostic values are slightly high. See help('pareto-k-diagnostic') for details.\n\n\nWarning: \n4 (3.3%) p_waic estimates greater than 0.4. We recommend trying loo instead.\n\n\n\n\n\n\n\n\nCompare the two models. Beta model has lower WAIC, so is the superior model.\n\n\n       elpd_diff se_diff\nmodel2   0.0       0.0  \nmodel1 -34.8       5.7  \n\n\nWarning: Accessing waic using '$' is deprecated and will be removed in a\nfuture release. Please extract the waic estimate from the 'estimates' component\ninstead.\n\nWarning: Accessing waic using '$' is deprecated and will be removed in a\nfuture release. Please extract the waic estimate from the 'estimates' component\ninstead.\n\n\n\n\n\nWarning: Accessing waic using '$' is deprecated and will be removed in a\nfuture release. Please extract the waic estimate from the 'estimates' component\ninstead.\n\nWarning: Accessing waic using '$' is deprecated and will be removed in a\nfuture release. Please extract the waic estimate from the 'estimates' component\ninstead."
  },
  {
    "objectID": "posts/2023-05-23/index.html",
    "href": "posts/2023-05-23/index.html",
    "title": "My Ordinal Function",
    "section": "",
    "text": "This is a function that links associative value to a probability distribution of choices. Given the choices are ordinal, a likert scale of 1 to 9, where 8 is larger than 7, but is not necessarily 8 times larger than 1, or twice as large as 4.\nIn neural networks, they sometimes use regularisation, to make the one-hot encoding less hot.\n\\[\\begin{align} \\alpha & = \\text{A parameter which sets the hotness} \\\\\nK & = \\text{The number of choices}\n\\end{align}\\]\n\\[ \\huge p = (1-\\alpha) ~\\cdot~[0,0,1] ~ +~ \\frac{\\alpha}{K}  \\]\n\n\n\n\n\nIts still quite binary, and doesn’t capture any ordinal features.\nReally we are looking for a unimodal distribution, centred around the associative value.\nThere are a few suggested ways of doing this. Poisson distribtions are not flexible enough. Binomial distributions dont work at extreme values. The beta distribution could work, but is hard to parameterise with only a mean or mode.\nBut from this paper, I found an alternative solution.\nhttps://www.sciencedirect.com/science/article/pii/S0925231220300618?via%3Dihub\n\\[ \\tau = \\text{Our inverse temperature parameter, essentially choice precision}\\]\n\\[\\begin{align} \\huge p_i~ &\\huge= exp\\left( - \\left| \\frac{ \\frac{i}{K} - V_t}{\\tau}\\right|\\right) \\left\\{i \\in \\mathbb{Z}~ | ~1 \\leqslant i \\leqslant K \\right\\} \\\\ \\huge p~ &\\huge =  \\text{Softmax}\\left(p_1,p_2,...,p_K\\right)\n\\end{align}\n\\]\nBy subtracting a label from ground truth, you see a measure of distance from ground truth. In this instance, associative value is ground truth, and the labels are K equal points along the unit interval. In FLARe this will be 9, to represent the nine possilbe choices on the scale.\n\n\n\n\n\nA low \\(\\tau\\) means a more precise choice, with further away choices much less likely than near choices (left). A higher \\(\\tau\\) means nearer choices are almost as likely, with further away choices still unlikely (middle). Finally a very high \\(\\tau\\) makes the distribution almost uniform, per the normal regularisation (right)."
  },
  {
    "objectID": "posts/2023-11-12/index.html",
    "href": "posts/2023-11-12/index.html",
    "title": "Noise & Bimodal",
    "section": "",
    "text": "Use Stan to generate data with fixed parameters.\nA normal distribution, mean: 3, and sigma: 1.\n\\[ y \\sim \\text{Normal}(\\mu,\\sigma) \\]\n\n\n\n\n\nThen use Stan to estimate parameters from this generated data.\n\n\n\n\n\nStan estimates a \\(\\mu\\) of 2.9781, and a \\(\\sigma\\) of 0.9763.\nWhich is 0.0219, and 0.0237 off reality.\n\n\n\nMore samples probably means better estimates.\nThough basically reaches optimality at 100 samples or so, definitely by 250.\n\n\n\n\n\n\n\n\n\n\n\nNow for some noize.\nAdding in an \\(\\epsilon\\) parameter, to add to the normal distribution like in a linear regression.\n\\[ y \\sim \\text{Normal}(\\mu,\\sigma_{\\mu}) + \\epsilon, ~ \\epsilon \\sim \\text{Normal}(0,\\sigma_{\\epsilon}) \\]\n\n\n\n\\(\\epsilon\\) is 10, \\(\\sigma\\) remains 1\n\n\n\n\n\nHow do the estimates fare with noise.\n\n\n\n\n\n\n\n\nStan estimates a \\(\\mu\\) of 2.5517, a \\(\\sigma\\) of 5.0032, and an \\(\\epsilon\\) of 5.1733\nWhich is 0.4483, -4.0032 , and 4.8267off reality.\nSo it struggles to unpick the noise from signal, i.e. measurement error from internal noise https://www.bmj.com/content/312/7047/1654\n\n\n\nPriors might help.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPriors appear far too informative. The model is too basic, with noise on top of noise indistingushable, without another dimension.\nA better model exists within the Stan user guide [https://mc-stan.org/docs/stan-users-guide/bayesian-measurement-error-model.html]\n\n\n\nStan can run mixture models. [https://mc-stan.org/docs/stan-users-guide/summing-out-the-responsibility-parameter.html]\nYou can have a mix of \\(K\\) normal distributions, with locations \\(\\mu_k\\), scales \\(\\sigma_k\\) and mixing proportions \\(\\lambda\\) within a \\(K\\)-simplex.\n\\[ p_y(y~ |~ \\lambda,\\mu,\\sigma) = \\sum^{K}_{k=1}\\lambda_k ~\\text{Normal}(y~|~\\mu_k,\\sigma_k)\\]\n\n\n\n\n\nAnd reverse estimate the parameters I put in.\n\n\n\n\n\n\n\n\n\n\n\nIt works, but interestingly, the chains get stuck on one or the other model, so for further analysis, you would have to compare chains rather than models.\nWhen assessing parameter estimates, the mode is probably more useful than the mean or median, given this non mixing."
  },
  {
    "objectID": "OrdinalFunction.html",
    "href": "OrdinalFunction.html",
    "title": "My Ordinal Function",
    "section": "",
    "text": "This is a function that links associative value to a probability distribution of choices. Given the choices are ordinal, a likert scale of 1 to 9, where 8 is larger than 7, but is not necessarily 8 times larger than 1, or twice as large as 4.\nIn neural networks, they sometimes use regularisation, to make the one-hot encoding less hot.\n\\[\\begin{align} \\alpha & = \\text{A parameter which sets the hotness} \\\\\nK & = \\text{The number of choices}\n\\end{align}\\]\n\\[ \\huge p = (1-\\alpha) ~\\cdot~[0,0,1] ~ +~ \\frac{\\alpha}{K}  \\]\n\n\n\n\n\nIts still quite binary, and doesn’t capture any ordinal features.\nReally we are looking for a unimodal distribution, centred around the associative value.\nThere are a few suggested ways of doing this. Poisson distribtions are not flexible enough. Binomial distributions dont work at extreme values. The beta distribution could work, but is hard to parameterise with only a mean or mode.\nBut from this paper, I found an alternative solution.\nhttps://www.sciencedirect.com/science/article/pii/S0925231220300618?via%3Dihub\n\\[ \\tau = \\text{Our inverse temperature parameter, essentially choice precision}\\]\n\\[\\begin{align} \\huge p_i~ &\\huge= exp\\left( - \\left| \\frac{ \\frac{i}{K} - V_t}{\\tau}\\right|\\right) \\left\\{i \\in \\mathbb{Z}~ | ~1 \\leqslant i \\leqslant K \\right\\} \\\\ \\huge p~ &\\huge =  \\text{Softmax}\\left(p_1,p_2,...,p_K\\right)\n\\end{align}\n\\]\nBy subtracting a label from ground truth, you see a measure of distance from ground truth. In this instance, associative value is ground truth, and the labels are K equal points along the unit interval. In FLARe this will be 9, to represent the nine possilbe choices on the scale.\n\n\n\n\n\nA low \\(\\tau\\) means a more precise choice, with further away choices much less likely than near choices (left). A higher \\(\\tau\\) means nearer choices are almost as likely, with further away choices still unlikely (middle). Finally a very high \\(\\tau\\) makes the distribution almost uniform, per the normal regularisation (right)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PhD_Blog",
    "section": "",
    "text": "Tim Kerr\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNov 12, 2023\n\n\nTim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNov 12, 2023\n\n\nTim Kerr\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr\n\n\nstan\n\n\n\n\n\n\n\n\n\n\n\nNov 12, 2023\n\n\nTim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJan 17, 2023\n\n\nTim Kerr\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr\n\n\nstan\n\n\n\n\n\n\n\n\n\n\n\nJan 5, 2023\n\n\nTim\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  }
]